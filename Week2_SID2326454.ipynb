{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quDlLWcAP31q"
   },
   "source": [
    "## MLP for Binary Classification\n",
    "\n",
    "In this lab, you will use the Ionosphere data binary (two-class) classification dataset to demonstrate an MLP for binary classification.\n",
    "\n",
    "This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n",
    "\n",
    "The dataset will be downloaded automatically using Pandas, but you can learn more in the links below.\n",
    "\n",
    "[Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n",
    "\n",
    "[Ionosphere Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n",
    "\n",
    "\n",
    "Your task for this is lab is to develop a Keras-based Multi-Layer Perceptron model for this data set. Remember the number of output layers is equal to the number of classes.\n",
    "\n",
    "Following we have provided some piece of code to you while you need to complete the rest of the code on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6086ipzNP31q"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "# Your code to import read_csv class from pandas\n",
    "from pandas import read_csv\n",
    "\n",
    "# Your code to import train_test_split class from sklearn. Follow link https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7755rFn_iDRj"
   },
   "source": [
    "# Read the dataset from the path below. Store the data in a pandas dataframe named 'df'\n",
    "\n",
    "Link to API - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "058u-qkXP31r"
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "# Your code to read the csv from the above path.\n",
    "df = read_csv(path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG3n2OHrjQsG"
   },
   "source": [
    "See the sample dataset. Print few rows of the dataset. Use dataframe.head() method.\n",
    "\n",
    "Link to API:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jx3JTj4sfUIt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo8Siqyxfhj7"
   },
   "source": [
    "Print the basic info of the dataset. Use dataframe.info() from pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VgN9rYV_fiag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       351 non-null    int64  \n",
      " 1   1       351 non-null    int64  \n",
      " 2   2       351 non-null    float64\n",
      " 3   3       351 non-null    float64\n",
      " 4   4       351 non-null    float64\n",
      " 5   5       351 non-null    float64\n",
      " 6   6       351 non-null    float64\n",
      " 7   7       351 non-null    float64\n",
      " 8   8       351 non-null    float64\n",
      " 9   9       351 non-null    float64\n",
      " 10  10      351 non-null    float64\n",
      " 11  11      351 non-null    float64\n",
      " 12  12      351 non-null    float64\n",
      " 13  13      351 non-null    float64\n",
      " 14  14      351 non-null    float64\n",
      " 15  15      351 non-null    float64\n",
      " 16  16      351 non-null    float64\n",
      " 17  17      351 non-null    float64\n",
      " 18  18      351 non-null    float64\n",
      " 19  19      351 non-null    float64\n",
      " 20  20      351 non-null    float64\n",
      " 21  21      351 non-null    float64\n",
      " 22  22      351 non-null    float64\n",
      " 23  23      351 non-null    float64\n",
      " 24  24      351 non-null    float64\n",
      " 25  25      351 non-null    float64\n",
      " 26  26      351 non-null    float64\n",
      " 27  27      351 non-null    float64\n",
      " 28  28      351 non-null    float64\n",
      " 29  29      351 non-null    float64\n",
      " 30  30      351 non-null    float64\n",
      " 31  31      351 non-null    float64\n",
      " 32  32      351 non-null    float64\n",
      " 33  33      351 non-null    float64\n",
      " 34  34      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code to print information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX_YFAb4kdl4"
   },
   "source": [
    "Print the shape of the dataframe. Select suitable API call from the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rlfCOssvf44O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekdoY2zkxU4"
   },
   "source": [
    "# Separate the input and output from the dataframe. Input is all columns besides last column. Output is the last column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_5bh8al2P31s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0.99539 ... -0.54487 0.18641 -0.453]\n",
      " [1 0 1.0 ... -0.06288 -0.13738 -0.02447]\n",
      " [1 0 1.0 ... -0.2418 0.56045 -0.38238]\n",
      " ...\n",
      " [1 0 0.94701 ... 0.00442 0.92697 -0.00577]\n",
      " [1 0 0.90608 ... -0.03757 0.87403 -0.16243]\n",
      " [1 0 0.8471 ... -0.06678 0.85764 -0.06151]]\n",
      "['g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n",
      " 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n",
      " 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n",
      " 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n",
      " 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n",
      " 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n",
      " 'b' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n",
      " 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n",
      " 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n",
      " 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n",
      " 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n",
      " 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g']\n"
     ]
    }
   ],
   "source": [
    "X = df.values[:, :-1]\n",
    "# Your code to get y - Hint y = df.values[:, some parameters]\n",
    "y = df.values[:, -1]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7y3GhJDloqk"
   },
   "source": [
    "We have converted everthing in X to 'float' and the letters in column y to the numbers in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qVtPf2F9lg17"
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ_aY4H3l9bI"
   },
   "source": [
    "Printing the genral information of the X and y in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BWBOMrBigew9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.       0.       0.99539 ... -0.54487  0.18641 -0.453  ]\n",
      " [ 1.       0.       1.      ... -0.06288 -0.13738 -0.02447]\n",
      " [ 1.       0.       1.      ... -0.2418   0.56045 -0.38238]\n",
      " ...\n",
      " [ 1.       0.       0.94701 ...  0.00442  0.92697 -0.00577]\n",
      " [ 1.       0.       0.90608 ... -0.03757  0.87403 -0.16243]\n",
      " [ 1.       0.       0.8471  ... -0.06678  0.85764 -0.06151]]\n",
      "[1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(351, 34)\n",
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "#LabelEncoder?\n",
    "# Your code to print X\n",
    "print(X)\n",
    "# Your code to print y\n",
    "print(y)\n",
    "# your code to print shape of X. Remember X is a numpy array\n",
    "print(X.shape)\n",
    "# your code to print shape of y. Remember y is a numpy array\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ltrLLqmkgW"
   },
   "source": [
    "* Separate X and y into training and test set with a ratio of your choice.\n",
    "* Print the shapes of the resulting arrays.\n",
    "* Get the number of features from X_train. Remember the number of features are the number of inputs.\n",
    "\n",
    "Use sklearn train_test_split class.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-CjFJcAMP31s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 34)\n",
      "(106, 34)\n",
      "(245,)\n",
      "(106,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to separate the data into trauning and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "\n",
    "# Your code to print shape of X_train\n",
    "print(X_train.shape)\n",
    "# Your code to print shape of X_test\n",
    "print(X_test.shape)\n",
    "# Your code to print shape of y_train\n",
    "print(y_train.shape)\n",
    "# Your code to print shape of y_test\n",
    "print(y_test.shape)\n",
    "\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQdqYXJ9pqzC"
   },
   "source": [
    "# Creating a Multi-layer Perceptron using Keras.\n",
    "We have added first and last layers. Create the hidden layers of your choise.\n",
    "You can chose any number of hidden layers and activation function of your chose\n",
    "https://keras.io/api/layers/core_layers/dense/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hhTE3u-_P31t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 10)                350       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 44        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399 (1.56 KB)\n",
      "Trainable params: 399 (1.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "model.add(Dense(4, activation='relu'))\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NtBU922rH67"
   },
   "source": [
    "In the next cell, we trained the above neural network model and tested its accuracy. As this concept has still not benn covered in the class, just run the code to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "krgB1SuRP31t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.6775 - accuracy: 0.6449\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6367\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6367\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6286\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6327\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6367\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6367\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6367\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6408\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6449\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6449\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6449\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.6571\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.6694\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.6939\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7102\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 66us/step - loss: 0.5287 - accuracy: 0.7265\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7265\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7388\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7469\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7592\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7837\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8000\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8000\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8041\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8286\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8408\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.4323 - accuracy: 0.8490\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8612\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8612\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8694\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8653\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8776\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3803 - accuracy: 0.8776\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3723 - accuracy: 0.8776\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3650 - accuracy: 0.8776\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8857\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3502 - accuracy: 0.8857\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3434 - accuracy: 0.8898\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3369 - accuracy: 0.8898\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3306 - accuracy: 0.8898\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8898\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8980\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.9020\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.9020\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3023 - accuracy: 0.9020\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.9020\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.9020\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.9102\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.9102\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.9102\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9102\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.9102\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.9102\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9102\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9102\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9184\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9184\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9184\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9143\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9143\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.9143\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9143\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9143\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9143\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9184\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9184\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9184\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9184\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9184\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9184\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9184\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9184\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9184\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9184\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9184\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9184\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9184\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9184\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 869us/step - loss: 0.2041 - accuracy: 0.9184\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9184\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9184\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9184\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9184\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9224\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9224\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9224\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1897 - accuracy: 0.9224\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1882 - accuracy: 0.9224\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1866 - accuracy: 0.9224\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1848 - accuracy: 0.9265\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9265\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9265\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9265\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9265\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9265\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9265\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9265\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1727 - accuracy: 0.9265\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1715 - accuracy: 0.9306\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 91us/step - loss: 0.1698 - accuracy: 0.9306\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9306\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9306\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9306\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9306\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9306\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9347\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1604 - accuracy: 0.9429\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9429\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9429\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1573 - accuracy: 0.9429\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1561 - accuracy: 0.9429\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1546 - accuracy: 0.9429\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9429\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9429\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9429\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9429\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1495 - accuracy: 0.9429\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9429\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 473us/step - loss: 0.1485 - accuracy: 0.9429\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9429\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9429\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1430 - accuracy: 0.9429\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1416 - accuracy: 0.9429\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9429\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9429\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9429\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9429\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1360 - accuracy: 0.9429\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1345 - accuracy: 0.9429\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9429\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9429\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9429\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1306 - accuracy: 0.9429\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1292 - accuracy: 0.9469\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.1286 - accuracy: 0.9469\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9469\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9429\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9429\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1239 - accuracy: 0.9469\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9469\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9469\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9469\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9469\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1191 - accuracy: 0.9469\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1181 - accuracy: 0.9469\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9469\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9469\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9469\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b90eaefaf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8868\n",
      "Test Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ReYGy_jsCh0"
   },
   "source": [
    "** How much accuracy have you got? Compare the accuracy with your peers. **\n",
    "** Now, change your model and activation function to get the better accuracy as compared to your peers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmeq5l1edZPg"
   },
   "source": [
    "## **Important:** Document in your lab logbook the accuracy of the improved model. Do not include any code or explanations in your lab logbook. Simply record the accuracy. For example, if the obtained accuracy is 0.98, then enter \"0.98\" in your lab logbook.\n",
    "\n",
    "## In addition to the accuracy, also document the output of the neural network as provided in Task 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFNL8fY2rd41"
   },
   "source": [
    "\n",
    "Next, we have provided the code to predict on an unknown value.\n",
    "We will cover these concepts later in the class. For now, just run the code to see the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXV7gQRAP31u",
    "outputId": "a5092aea-3cad-4009-de83-956caa73ecba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Predicted: 0.973\n"
     ]
    }
   ],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,\n",
    "       0.83398,-0.37708,1,0.03760,0.85243,-0.17755,\n",
    "       0.59755,-0.44945,0.60536,-0.38223,0.84356,\n",
    "       -0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,\n",
    "       -0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,\n",
    "       -0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 10)                350       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 30)                630       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 40)                1240      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2481 (9.69 KB)\n",
      "Trainable params: 2481 (9.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.6082\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6286\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6408\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6694\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7061\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7429\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7673\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8122\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8490\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8898\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.9061\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.9061\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9265\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9388\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9347\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9388\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9429\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9551\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9510\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9551\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9592\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1368 - accuracy: 0.9551\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 97us/step - loss: 0.1233 - accuracy: 0.9592\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 84us/step - loss: 0.1184 - accuracy: 0.9633\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9673\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9673\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9837\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9796\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9796\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9837\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9837\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9837\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9837\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9837\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9837\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9837\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9837\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9837\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9837\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9837\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9837\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9837\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9837\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9837\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9837\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9837\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9837\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9837\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9837\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9837\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9837\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9837\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9837\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9837\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9837\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9837\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9837\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0421 - accuracy: 0.9837\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 289us/step - loss: 0.0362 - accuracy: 0.9837\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 394us/step - loss: 0.0382 - accuracy: 0.9878\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 765us/step - loss: 0.0360 - accuracy: 0.9837\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9837\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9878\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9837\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9878\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9878\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9878\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9918\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 794us/step - loss: 0.0278 - accuracy: 0.9878\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 517us/step - loss: 0.0272 - accuracy: 0.9918\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9918\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9959\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9918\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9918\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9959\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9959\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9959\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0215 - accuracy: 0.9959\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 339us/step - loss: 0.0240 - accuracy: 0.9959\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 974us/step - loss: 0.0199 - accuracy: 0.9959\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 850us/step - loss: 0.0201 - accuracy: 0.9959\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9959\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9959\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9959\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9959\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0181 - accuracy: 0.9959\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 94us/step - loss: 0.0171 - accuracy: 0.9959\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 612us/step - loss: 0.0145 - accuracy: 0.9959\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9959\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9959\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0132 - accuracy: 0.9959\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 590us/step - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9959\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9959\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9959\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9959\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0087 - accuracy: 0.9959\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 612us/step - loss: 0.0111 - accuracy: 0.9959\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9959\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9959\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9959\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9959\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9959\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9959\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9959\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9959\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9959\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9959\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9959\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 610us/step - loss: 0.0085 - accuracy: 0.9959\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 447us/step - loss: 0.0071 - accuracy: 0.9959\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 316us/step - loss: 0.0068 - accuracy: 0.9959\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 399us/step - loss: 0.0077 - accuracy: 0.9959\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 38us/step - loss: 0.0067 - accuracy: 0.9959\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0069 - accuracy: 0.9959\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0064 - accuracy: 0.9959\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9959\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9959\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0056 - accuracy: 0.9959\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 268us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 592us/step - loss: 0.0078 - accuracy: 0.9959\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9959\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9959\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 416us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9959\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9959\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 135us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 275us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 652us/step - loss: 0.0031 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b90fa30ca0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.9245\n",
      "Test Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 10)                350       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 25)                275       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 35)                910       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 45)                1620      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 46        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3201 (12.50 KB)\n",
      "Trainable params: 3201 (12.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.6411 - accuracy: 0.6122\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6122\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 514us/step - loss: 0.5818 - accuracy: 0.6204\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 252us/step - loss: 0.5580 - accuracy: 0.6653\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7143\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7673\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8204\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8531\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8898\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8939\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8898\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.9061\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9102\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9265\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9347\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9388\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9429\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9429\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9551\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9469\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9633\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9673\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9714\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9714\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9633\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9755\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9796\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9837\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9796\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9837\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9837\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9837\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9878\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9878\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9837\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9878\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9878\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 787us/step - loss: 0.0607 - accuracy: 0.9878\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 632us/step - loss: 0.0574 - accuracy: 0.9878\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 478us/step - loss: 0.0579 - accuracy: 0.9837\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9878\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9918\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9878\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9918\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9918\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9918\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9959\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9918\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9959\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9959\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9918\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9959\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9959\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0313 - accuracy: 0.9959\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9959\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9959\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9959\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9959\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9959\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9959\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9959\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9959\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9959\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9959\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0242 - accuracy: 0.9959\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9959\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9959\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9959\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9959\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9959\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9959\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9959\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9959\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9959\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9959\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9959\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9959\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9959\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9959\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 816us/step - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9959\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9959\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9959\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9959\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9959\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9959\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0088 - accuracy: 0.9959\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0091 - accuracy: 0.9959\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0063 - accuracy: 0.9959\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 311us/step - loss: 0.0094 - accuracy: 0.9959\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 421us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 594us/step - loss: 0.0063 - accuracy: 0.9959\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9959\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9959\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9959\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9959\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 547us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 707us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9959\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9959\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9959\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9959\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 323us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 216us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 636us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 737us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 108us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 345us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 327us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 375us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 377us/step - loss: 0.0017 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b90fa62440>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9340\n",
      "Test Accuracy: 0.934\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 10)                350       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 35)                385       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 45)                1620      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 55)                2530      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4941 (19.30 KB)\n",
      "Trainable params: 4941 (19.30 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(55, activation='relu'))\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 1s 1ms/step - loss: 0.6878 - accuracy: 0.6245\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6204\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6286\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 920us/step - loss: 0.6045 - accuracy: 0.6490\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6694\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7265\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8367\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8776\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 586us/step - loss: 0.3732 - accuracy: 0.8816\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8898\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.9020\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8857\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9020\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9061\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9184\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9184\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9306\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9265\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9347\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 720us/step - loss: 0.1538 - accuracy: 0.9388\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9429\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9469\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9551\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9633\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9551\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 551us/step - loss: 0.1018 - accuracy: 0.9633\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 339us/step - loss: 0.0952 - accuracy: 0.9592\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9673\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9714\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9755\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9796\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9837\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9714\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9837\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9755\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 874us/step - loss: 0.0571 - accuracy: 0.9837\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 664us/step - loss: 0.0558 - accuracy: 0.9837\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9837\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9878\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9878\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9878\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9878\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9878\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9918\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9918\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9918\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 961us/step - loss: 0.0324 - accuracy: 0.9918\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 475us/step - loss: 0.0294 - accuracy: 0.9959\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9959\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9959\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9959\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9959\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9959\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9959\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9959\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9959\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9959\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 850us/step - loss: 0.0194 - accuracy: 0.9959\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 653us/step - loss: 0.0185 - accuracy: 0.9959\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 370us/step - loss: 0.0192 - accuracy: 0.9959\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 300us/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9959\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9959\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9959\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9959\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9959\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9959\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9959\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9959\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9959\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9959\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9959\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9959\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9959\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 670us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 819us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 723us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 682us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 627us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 642us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 694us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 749us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 776us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 747us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 676us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 748us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 599us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 587us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 610us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 540us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 614us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 706us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 515us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 737us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0025 - accuracy: 1.0000 \n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 311us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 360us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 633us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.5846e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.5857e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.5401e-04 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.9898e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.9698e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.6363e-04 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.8364e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 7.8129e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.8989e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 7.8955e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 7.9896e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.5651e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 920us/step - loss: 8.9094e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 464us/step - loss: 8.8281e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 529us/step - loss: 7.7680e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b90fa0d060>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.9340\n",
      "Test Accuracy: 0.934\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNFK4kV9P31u"
   },
   "source": [
    "### Try out the same model with Keras Functional models!\n",
    "Refer to [Keras](https://keras.io/) for more details and tutorials for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55050 (215.04 KB)\n",
      "Trainable params: 55050 (215.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-2.0.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot) (3.0.9)\n",
      "Downloading pydot-2.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/2\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3437 - accuracy: 0.9031 - val_loss: 0.1870 - val_accuracy: 0.9458\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9513 - val_loss: 0.1594 - val_accuracy: 0.9513\n",
      "313/313 - 0s - loss: 0.1565 - accuracy: 0.9509 - 281ms/epoch - 898us/step\n",
      "Test loss: 0.15649296343326569\n",
      "Test accuracy: 0.9509000182151794\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
